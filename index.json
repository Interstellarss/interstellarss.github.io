[{"categories":["学习笔记"],"content":"简单介绍DBMS的概念以及涵盖的主题","date":"2020-11-04","objectID":"/posts/database/datanbank-1/","tags":["Database"],"title":"初识数据库","uri":"/posts/database/datanbank-1/"},{"categories":["学习笔记"],"content":"Why use a DBMS ？ 我想这是我们首先要回答的问题： Data independence 这意味着我们不需要知道数据是如何具体地被储存在disk上面，而只需要了解更高级别的数据模型，以便有效的访问数据。 Efficient access 这涉及到如何访问数据库中的数据，如何检索，使用一些检索，进行比较查询之类的功能。因为不适用DBMS而在一个普通的file system中这会涉及到Beschränkte Zugriffmöglichkeiten的问题，其中这些数据并没有互“相关联”，一组数据的信息与另一组的信息并没有逻辑上的联系。 Data integrity 这会涉及到一个”integrity constraints“的概念，举例来说，有一个公司要找更多的人，但是预算不一定够，于是每次要雇佣某个人，都要去检查这个约束，而如果不使用DBMS则可能会造成Interitätsverletzung的情况出现。 Security 如果使用DBMS，则更容易管理数据库和控制数据库的访问权限，因为并不是所有的用户都有权限去访问数据库各种各样的数据。 Concurrent access 这其实是可以归属于Verlust von Daten这一类的问题，而在DBMS中则可以很好的避免。 Recovery from crashes 数据库管理系统有一个复杂的恢复组件，以支持用户在所有可预见的错误情况下防止数据丢失。 ","date":"2020-11-04","objectID":"/posts/database/datanbank-1/:0:1","tags":["Database"],"title":"初识数据库","uri":"/posts/database/datanbank-1/"},{"categories":["学习笔记"],"content":"Data Models A data model is a collection of high-level constructs for describing stored data that hides low-level storage details. 或者引用书中的话： Das Datenmodell ist somit analog zu einer Programmiersprache: Es legt die generischen Strukturen und Operatoren fest, die man zur Modellierung einer bestimmten Anwendung ausnutzen kann. Eine Programmiersprache legte die Typkonstruktoren und Sprachkonstruckte fest, mit deren Hilfe man spezifische Anwendungsprogramme realisiert.1 Data Models 其实更像是编程语言，定义了为了特定使用的结构和操作。 三个主要的data model 是： Network data Model Hierarchical data Model Relational data Model 当然我们后面会关注的的其实只有Relational data model就是了 :) 就像名字所描绘的那样，在Relational data Model中描述了所有的“relations”， 包括“entities”and“relationships”，其中的主要概念是：relation， 对于relation我们基本上可以想像成一系列的“Tabellen”，也即“table with rows and columns”,更深入的理解为“table”与“table”之间的关系。举例来说：对于，学生听讲座，我们有学生组成的表，Vorlesung组成的表，还有“听”的表，所以才有学生组成的表“听”讲座组成的表。同时，每一个“relation”都有一个“schema”或者说“Spalten”，来描述内部储存的数据，也即各列的意义，所表示的“attributes”。 ","date":"2020-11-04","objectID":"/posts/database/datanbank-1/:0:2","tags":["Database"],"title":"初识数据库","uri":"/posts/database/datanbank-1/"},{"categories":["学习笔记"],"content":"Datenabstraktion 下图展示了DBMS的三个抽象层级，分别是physical Ebene, logische Ebene(对应 conceptual Schema)，以及die Schichten(对应external Schema)。 Level of Abstraction 1 Die physische Ebene: 描述了data是如何储存的，并且定义了使用的files和indexes，换句话说总结了上一层逻辑层中的“relations”是如何存储在储存设备上的。 Die logische Ebene: 定义了基于data model的逻辑结构，也即确定了“Datenbankschema”，也就是如何去组织数据，值得注意的是也就是在这里描述了前文中提到的“data model”。 Die Sichten: 这里其实已经是“external schema”的层面了，在这里描述了不同的用户如何访问“看见”这些数据，不同用户可能访问同一个数据库但是看到的数据可能是不同的，我们可以说这里是不同“views”的集合，允许数据访问被客制化，并且不会储存这些客制化的表格:) Datenunabhängigkeit Logische Datenunabhängigkeit: 当然AKA logical data independence, protection from changes in logical structure of the data.值得注意的是adding new entities 是属于logical 这一层的，因为当你新加入实体的时候，是conceptual schema这一层的概念。 Physische Datenunabhängigkeit: AKA physical data independence, protection from changes in physical structure of data. 举例来说，当physical schema 变化，可能会改变引索的属性、以及索引的方式，但是上层并不清楚这些变化。 Datenbankschema und Ausprägung 不妨先来看看书中的定义： “Das Datenbankschema legt die Struktur der abspeicherbaren Datenobjekte fest. Das Schema sagt also noch nichts über die individuellen Datenobjekte \" ","date":"2020-11-04","objectID":"/posts/database/datanbank-1/:0:3","tags":["Database"],"title":"初识数据库","uri":"/posts/database/datanbank-1/"},{"categories":["学习笔记"],"content":"Queries in a DBMS Questions involving the data stored in a DBMS are called queries. A query language is used to pose queries. Structural Query Language(SQL), which supports a rich class of queries, has contributed greatly to the success of relational DBMS. Relational algebra and relational calculus are two formal query languages providing theoretical foundation for relational DBMS. ","date":"2020-11-04","objectID":"/posts/database/datanbank-1/:0:4","tags":["Database"],"title":"初识数据库","uri":"/posts/database/datanbank-1/"},{"categories":["学习笔记"],"content":"Summary 上面的内容从比较宏观的视角讨论了DBMS中的一些主题，像是Datenmodel啊，SQL语言的基础概念啊，relational algebra啊，接下来我们要讨论的就是非常著名的ER-Model了呢。 [Kemper, Alfons and Eickler, André, Datenbanksysteme: Eine Einführung, 7.,ISBN:9783486590180] ↩︎ ","date":"2020-11-04","objectID":"/posts/database/datanbank-1/:0:5","tags":["Database"],"title":"初识数据库","uri":"/posts/database/datanbank-1/"},{"categories":["学习笔记"],"content":"游戏物理相关主题概况","date":"2020-10-30","objectID":"/posts/game_physics/game_physics_1/","tags":["Physics in Games"],"title":"关于游戏中物理系统的一些小事 -- 导引篇 - 1","uri":"/posts/game_physics/game_physics_1/"},{"categories":["学习笔记"],"content":"假期过后又要开启新的系列了呢，这次带来的是有关游戏中的物理系统的呢。如果说在computer graphic中我们学习到的更多是有关空间类的法术，那么在游戏物理中我们将会领略到「模拟类法术」的魅力。不言自明的是在「模拟类法术」下也有很多不同的分支，我们将从「物理模拟」以及「游戏中的物理系统」的角度来认识。 在这个过程中，我们将会获得对真实现象进行物理模拟的「法术」知识，了解所讨论的物理模型并通过相应的numerical approaches来求解他们。我以为能够用编程语言来实现其中的各种模拟算法和integration methods才可以说是有学到「法术」，当然我这里会分享一些C++的实现，主要会关注以下领域的概念和方法：刚体建模，碰撞检测方法，弹簧和可形变物体，流体建模及模拟，还有numerical simulation基础，以及粒子系统（partical systems）。 接下来会介绍一些用于模拟上面提到的模型时用到的一些数学知识。 ","date":"2020-10-30","objectID":"/posts/game_physics/game_physics_1/:0:0","tags":["Physics in Games"],"title":"关于游戏中物理系统的一些小事 -- 导引篇 - 1","uri":"/posts/game_physics/game_physics_1/"},{"categories":["学习笔记"],"content":"常微分方程（ordinary differential equation） 在数学分析中，常微分方程（ODE）是未知函数只含有一个自变量的微分方程。 ","date":"2020-10-30","objectID":"/posts/game_physics/game_physics_1/:0:1","tags":["Physics in Games"],"title":"关于游戏中物理系统的一些小事 -- 导引篇 - 1","uri":"/posts/game_physics/game_physics_1/"},{"categories":null,"content":"Test test ","date":"2020-10-29","objectID":"/posts/first_post/:0:0","tags":null,"title":"First_post","uri":"/posts/first_post/"},{"categories":["学习笔记"],"content":"探索计算机网络OSI模型中的网络层的故事.","date":"2020-07-06","objectID":"/posts/computernetwork/network-layer/","tags":["computer network"],"title":"作为带路专家的网络层","uri":"/posts/computernetwork/network-layer/"},{"categories":["学习笔记"],"content":"在这里我们会认识到网络层提供的两种不同服务和网络层的核心也即–IP协议. 我们能够理解: 虚拟互连网络的概念. IP地址与物理地址的关系 传统的分类的IP地址（包括子网掩码) ","date":"2020-07-06","objectID":"/posts/computernetwork/network-layer/:0:0","tags":["computer network"],"title":"作为带路专家的网络层","uri":"/posts/computernetwork/network-layer/"},{"categories":["学习笔记"],"content":"地址解析协议ARP 在实际应用中，我们经常会遇到这样的问题：已经知道了一个机器（主机或路由器）的IP地址，需要找出其相应的硬件地址。地址解析协议ARP就是用来解决这样的问题的。由于是IP协议使用了ARP协议，因此通常就把ARP协议划归网络层。但ARP协议的用途是为了从网络层使用的IP地址，解析出在数据链路层使用的硬件地址。 下面就介绍ARP协议的要点。 我们知道，网络层使用的是IP地址，但在实际网络的链路上传送数据帧时，最终还是必须使用该网络的硬件地址。但IP地址和下面的网络的硬件地址之间由于格式不同而不存在简单的映射关系（例如，IP地址有32位，而局域网的硬件地址是48位）。此外，在一个网络上可能经常会有新的主机加入进来，或撤走一些主机。更换网络适配器也会使主机的硬件地址改变。地址解析协议 ARP解决这个问题的方法是在主机ARP高速缓存中存放一个从IP地址到硬件地址的映射表，并且这个映射表还经常动态更新（新增或超时删除）。 每一台主机都设有一个ARP高速缓存（ARP cache） ，里面有本局域网上 的各主机和路由器的IP地址到硬件地址的映射表，这些都是该主机目前知道的一些地址。那么主机怎样知道这些地址呢？我们可以通过下面的例子来说明。 当主机A要向本局域网 上的某台主机B发送IP数据报时，就先在其ARP高速缓存中查看有无主机B的IP地址。如有，就在ARP高速缓存中查出其对应的硬件地址，再把这个硬件地址写入MAC帧，然后通过局域网把该MAC帧发往此硬件地址。 也有可能查不到主机B的IP地址的项目。这可能是主机B才入网，也可能是主机A刚刚加电，其高速缓存还是空的。在这种情况下，主机A就自动运行ARP，然后按以下步骤找出主机B的硬件地址。 1）ARP进程在本局域网上广播发送一个ARP请求分组. ARP请求分组的主要内容的一个例子是：“我的IP地址是209.0.0.5，硬件地址是00-00-C0-15-AD-18。我想知道IP地址为209.0.0.6的主机的硬件地址。” 2）在本局域网上的所有主机上运行的ARP进程都收到此ARP请求分组。 3）主机B的IP地址与ARP请求分组中要查询的IP地址一致，就收下这个ARP请求分组，并向主机A发送ARP响应分组，同时在这个ARP响应分组中写入自己的硬件地址。由于其余的所有主机的IP地址都与ARP请求分组中要查询的IP地址不一致，因此都不理睬这个ARP请求分组. ARP响应分组的主要内容是：“我的IP地址是209.0.0.6，我的硬件地址是08-00-2B-00-EE-0A。”请注意：虽然ARP请求分组是广播发送的，但ARP响应分组是普通的单播，即从一个源地址发送到一个目的地址。 4）主机A收到主机B的ARP响应分组后，就在其ARP高速缓存中写入主机B的IP地址到硬件地址的映射。 当主机A向B发送数据报时，很可能以后不久主机B还要向A发送数据报，因而主机B也可能要向A发送ARP请求分组。为了减少网络上的通信量，主机A在发送其ARP请求分组时，就把自己的IP地址到硬件地址的映射写入ARP请求分组。当主机B收到A的ARP请求分组时，就把主机A的这一地址映射写入主机B自己的ARP高速缓存中。以后主机B向A发送数据报时就很方便了。 可见ARP高速缓存非常有用。如果不使用ARP高速缓存，那么任何一台主机只要进行一次通信，就必须在网络上用广播方式发送ARP请求分组，这就使网络上的通信量大大增加。ARP把已经得到的地址映射保存在高速缓存中，这样就使得该主机下次再和具有同样目的地址的主机通信时，可以直接从高速缓存中找到所需的硬件地址而不必再用广播方式发送ARP请求分组。 ARP对保存在高速缓存中的每一个映射地址项目都设置生存时间 （例如，10～20分钟）。凡超过生存时间的项目就从高速缓存中删除掉。设置这种地址映射项目的生存时间是很重要的。设想有一种情况。主机A和B通信。A的ARP高速缓存里保存有B的硬件地址。但B的网络适配器突然坏了，B立即更换了一块，因此B的硬件地址就改变了。假定A还要和B继续通信。A在其ARP高速缓存中查找到B原先的硬件地址，并使用该硬件地址向B发送数据帧。但B原先的硬件地址已经失效了，因此A无法找到主机B。但是过了一段不长的生存时间，A的ARP高速缓存中已经删除了B原先的硬件地址，于是A重新广播发送ARP请求分组，又找到了B。 请注意，ARP是解决同一个局域网上 的主机或路由器的IP地址和硬件地址的映射问题。从IP地址到硬件地址的解析是自动进行的，主机的用户对这种地址解析过程是不知道的 。只要主机或路由器要和本网络上的另一个已知IP地址的主机或路由器进行通信，ARP协议就会自动地把这个IP地址解析为链路层所需要的硬件地址。 ARP ","date":"2020-07-06","objectID":"/posts/computernetwork/network-layer/:0:1","tags":["computer network"],"title":"作为带路专家的网络层","uri":"/posts/computernetwork/network-layer/"},{"categories":["学习笔记"],"content":"IPv4 IP数据报的格式能够说明IP协议都具有什么功能。一个IP数据报由首部和数据两部分组成。首部的前一部分是固定长度 ，共20字节，是所有IP数据报必须具有的。在首部的固定部分的后面是一些可选字段 ，其长度是可变的。下面介绍首部各字段的意义。 版本(Version) 占4位，指IP协议的版本。通信双方使用的IP协议的版本必须一致。目前广泛使用的IP协议版本号为4（即IPv4）. 首部长度 占4位，可表示的最大十进制数值是15。请注意，首部长度字段所表示数的单位是32位字（1个32位字长是4字节）。因为IP首部的固定长度是20字节，因此首部长度字段的最小值是5（即二进制表示的首部长度是0101）。而当首部长度为最大值1111时（即十进制数的15），就表明首部长度达到最大值15个32位字长，即60字节。当IP分组的首部长度不是4字节的整数倍时，必须利用最后的填充字段加以填充。因此IP数据报的数据部分永远在4字节的整数倍时开始，这样在实现IP协议时较为方便。首部长度限制为60字节的缺点是有时可能不够用。但这样做是希望用户尽量减少开销。最常用的首部长度是20字节（即首部长度为0101），这时不使用任何选项。 区分服务 占8位，用来获得更好的服务。这个字段在旧标准中叫做服务类型 ，但实际上一直没有被使用过。 总长度 总长度指首部和数据之和的长度，单位为字节。总长度字段为16位，因此数据报的最大长度为2 16 –1＝65535字节。然而实际上传送这样长的数据报在现实中是极少遇到的。 ","date":"2020-07-06","objectID":"/posts/computernetwork/network-layer/:0:2","tags":["computer network"],"title":"作为带路专家的网络层","uri":"/posts/computernetwork/network-layer/"},{"categories":["学习笔记"],"content":"IP层转发分组的流程 我们知道在路由器中会有路由表,但是如果由路由表指出到每一台主机该如何转发,那样未免会使得路由表太过庞大, 但是如果路由表只是指出到某个网络该如何转发,那么该路由表就只会包括网络数的项目,这样就大大减小了需要储存的项目, 我们不必关心某个网络内部具体的拓扑以及具体有多少太设备连接在这个网络上, 因为是从一个路由器转发到下一个路由器. 路由表中的项目最主要的是以下两个信息: $$ (目的网络地址, 下一跳地址) $$ 这里只是IP层怎样根据路由表的内容 ","date":"2020-07-06","objectID":"/posts/computernetwork/network-layer/:0:3","tags":["computer network"],"title":"作为带路专家的网络层","uri":"/posts/computernetwork/network-layer/"},{"categories":["学习笔记"],"content":"网际控制报文协议–ICMP(Internet Control Message Protocol) 为了更有效地转发IP数据报和提高成功交付的机会,在网络层使用了ICMP协议. ICMP协议允许主机或路由器报告差错情况和提供有关异常情况的报告. 值得注意的是ICMP并不是高层协议, 反而仍然是网络层的协议,因为ICMP的报文装在IP数据报中,作为其中的数据部分. 在前面关于数据包首部结构的介绍中 “TOS” 和 “Protocol” 即是与ICMP 有关的. 教授slide中给出的描述也是极好的: Das Internet Control Message Protocol (ICMP) dient dazu, • in derartigen Fällen den Absender über das Problem zu benachrichtigen und • stellt zusätzlich Möglichkeiten bereit, um z. B. • die Erreichbarkeit von Hosts zu prüfen („Ping“) oder • Pakete umzuleiten (Redirect). ICMP报文的种类 ","date":"2020-07-06","objectID":"/posts/computernetwork/network-layer/:0:4","tags":["computer network"],"title":"作为带路专家的网络层","uri":"/posts/computernetwork/network-layer/"},{"categories":["学习笔记"],"content":"IPv6 IPv6基本首部 IPv4的地址耗尽后,我们很自然需要拓展IP地址块,于是就有了IPv6. IPv6仍然支持无连接的传送,但将协议数据单元PDU称为分组,而不是IPv4的数据报. IPv6的主要变化如下: 更大的地址空间,将IPv4的32位增大到4倍, 即增加到128位. 扩展的地址层次结构. 灵活的首部格式 改进的选项 允许协议继续扩充 IPv6首部改为8字节对齐 (即首部长度必须是8字节的整数倍),原来IPv4首部是4字节对齐. 与IPv4相比, IPv6对首部中的某些字段进行了如下的更改: 取消了首部的长度字段,因为其首部长度是固定的(40字节) 取消了服务类型(TOS)字段,因为优先级和流标号字段实现了服务类型字段的功能 取消了总字段长度,改用有效荷载长度字段 取消了标识, 标志和片偏移字段,但作用是一样的 取消了协议字段 取消了检验和字段 取消了可选字段 IPv4-Header (oben) und IPv6-Header (unten) im Vergleich IPv6基本首部各段作用 IPv6 Header 版本(version) 占4位, 指明了协议的版本, 对IPv6该字段是6 通信量类(traffic class) 占8位. 这是为了区分不同的IPv6数据报的类别或优先级. 目前正在进行不同的通信量性能的实验. 流标号(flow label) 占20位. IPv6的一个新的机制是支持资源预分配,并且允许路由器把每一个数据报与一个给定的资源分配相联系. IPv6提出流(flow)的抽象概念. 所谓 “流\"就是互联网络上从特定源点到特定终点(单播或多播)的一系列数据报(), 而在这个\"流\"所经过的路径上的路由器都保证指明的服务质量. 所有属于同一个流的数据报都具有同样的流标号. 因此, 流标号对于实时音频/视频数据的传送特别有用. 有效载荷长度(payload length) 占16位. 它指明IPv6数据报除基本首部以外的字节数(所有扩展首部都计算在有效载荷之内). 这个字段的最大值是64KB(65535字节) 下一个首部(next header) 占8位. 它相当于IPv4协议字段的的可选字段. 跳数限制(hop limit) 占8位. 用来防止数据报 源地址 占128位. 是数据报的发送端的地址. 目的地址 占128位. 是数据报的接收端的IP地址. 下面我们来介绍一下IPv6的拓展首部 大家知道，IPv4的数据报如果在其首部中使用了选项，那么沿着数据报传送的路径上的每一个路由器都必须对这些选项一一进行检查，这就降低了路由器处理数据报的速度。然而实际上很多的选项在途中的路由器上是不需要检查的（因为不需要使用这些选项的信息）。IPv6把原来IPv4首部中选项的功能都放在扩展首部中，并把扩展首部留给路径两端的源点和终点的主机来处理，而数据报途中经过的路由器都不处理这些扩展首部 （只有一个首部例外，即逐跳选项扩展首部），这样就**大大提高了路由器的处理效率 **。 我们大概会碰到这六种扩展首部:（1）逐跳选项；（2）路由选择；（3）分片；（4）鉴别；（5）封装安全有效载荷；（6）目的站选项。 每一个扩展首部都由若干个字段组成，它们的长度也各不同。但所有扩展首部的第一个字段都是8位的“下一个首部”字段。此字段的值指出了在该扩展首部后面的字段是什么。当使用多个扩展首部时，应按以上的先后顺序出现。高层首部总是放在最后面。 IPv6的地址 一般来说, 一个IPv6数据报的目的地址可以是以下三种基本类型地址之一: 单播(unicast) 单播就是点对点通信 多播(multicast) 任播(anycast) IPv6把实现IPv6的主机和路由器均称为结点 。由于一个结点可能会使用多条链路与其他的一些结点相连，因此一个结点可能有多个与链路相连的接口。这样，IPv6给结点的每一个接口指派一个IP地址。一个结点可以有多个单播地址，而其中任何一个地址都可以当作到达该结点的目的地址。 ICMPv6 和IPv4一样,IPv6也不保证数据报的可靠交付,因为互联网中的路由器可能会丢弃数据报. 因此IPv6也需要使用ICMP来反馈一些差错信息. 新的版本成为IPv6, 它比ICMPv4要复杂得多. 地址解析协议ARP和IGMP的功能都已被合并到ICMPv6中. 新旧版本中的网络层的比较 ICMPv6是面向报文的协议，它利用报文来报告差错，获取信息，探测邻站或管理多播通信。ICMPv6还增加了几个定义报文功能及含义的其他协议。在对ICMPv6报文进行归类时，不同的文献和RFC文档使用了不同的策略，有的把其中的一些报文定义为ICMPv6报文，而把另一些报文定义为邻站发现 ND（Neighbor-Discovery）报文, **使用NDP协议(Neighbor Discovery Protocol)**或多播听众交付 MLD（Multicast Listener Delivery）报文。其实所有这些报文都应当是ICMPv6报文，只是功能和作用不同而已。因此我们把这些报文都列入ICMPv6的不同类别。使用这种分类方法的原因是所有这些报文都具有相同的格式，并且所有报文类型都由ICMPv6协议处理。 ICMPv6报文的结构: ICMPv6 ","date":"2020-07-06","objectID":"/posts/computernetwork/network-layer/:0:5","tags":["computer network"],"title":"作为带路专家的网络层","uri":"/posts/computernetwork/network-layer/"},{"categories":["学习笔记"],"content":"Routing Longest Prefix Matching(最长前缀匹配) 在使用CIDR时，由于采用了网络前缀这种记法，IP地址由网络前缀和主机号这两个部分组成，因此在路由表中的项目也要有相应的改变。这时，每个项目由“网络前缀 ”和“下一跳地址 ”组成。但是在查找路由表时可能会得到不止一个匹配结果 。这样就带来一个问题：我们应当从这些匹配结果中选择哪一条路由呢？ 正确的答案是：应当从匹配结果中选择具有最长网络前缀的路由。这叫做最长前缀匹配 （longest-prefix matching），这是因为网络前缀越长，其地址块就越小，因而路由就越具体(more specific)。最长前缀匹配又称为最长匹配 或最佳匹配 . Die Routingtabelle wird von längeren Präfixen (spezifischeren Routen) hin zu kürzeren Präfixen (weniger spezifische Routen) durchsucht. Der erste passende Eintrag liefert das Gateway (Next-Hop) eines Pakets. Diesen Prozess bezeichnet man als Longest Prefix Matching. ","date":"2020-07-06","objectID":"/posts/computernetwork/network-layer/:0:6","tags":["computer network"],"title":"作为带路专家的网络层","uri":"/posts/computernetwork/network-layer/"},{"categories":["学习笔记"],"content":"first draft","date":"2020-06-07","objectID":"/posts/seminar-hpc/shared-memory-parallelism_2/","tags":["parallel computing","Seminar-HPC"],"title":"当我们谈论 shared memory parallelism 的时候我们在谈论些什么--提升篇","uri":"/posts/seminar-hpc/shared-memory-parallelism_2/"},{"categories":["学习笔记"],"content":"这次带来的是提升篇，其实就是seminar要交的paper的first draft，倒也算是偷懒的一种方式吧。 ","date":"2020-06-07","objectID":"/posts/seminar-hpc/shared-memory-parallelism_2/:0:0","tags":["parallel computing","Seminar-HPC"],"title":"当我们谈论 shared memory parallelism 的时候我们在谈论些什么--提升篇","uri":"/posts/seminar-hpc/shared-memory-parallelism_2/"},{"categories":["学习笔记"],"content":"A brief Overview on Shared Memory Parallelism in Parallel Computing ","date":"2020-06-07","objectID":"/posts/seminar-hpc/shared-memory-parallelism_2/:1:0","tags":["parallel computing","Seminar-HPC"],"title":"当我们谈论 shared memory parallelism 的时候我们在谈论些什么--提升篇","uri":"/posts/seminar-hpc/shared-memory-parallelism_2/"},{"categories":["学习笔记"],"content":"1. Why parallel? To speed up, while we are facing the limitation of current transistors and increasing energy consumption. Now that we know it is necessary and lots of privilege besides you need to reconstruct your program yourself rather than automatically distributed by APIs in a serial way. So, it then leads to the following question: how do we write parallel programs? Truth be told, there are number of possible answers to this question, while most of them share the idea of partitioning the work among cores. The two commonly used approach for this: task-parallelism and data-parallelism. In task-parallelism, we partition the problems into separately tasks that will be carried out in cores. While in data-parallelism each core carries out roughly similar operations on its part of data. ","date":"2020-06-07","objectID":"/posts/seminar-hpc/shared-memory-parallelism_2/:1:1","tags":["parallel computing","Seminar-HPC"],"title":"当我们谈论 shared memory parallelism 的时候我们在谈论些什么--提升篇","uri":"/posts/seminar-hpc/shared-memory-parallelism_2/"},{"categories":["学习笔记"],"content":"2. As it was mentioned above, when we write programs that are explicitly parallel, we will be focusing on two major types of parallel systems: shared-memory and distributed-memory. What is the idea of shared memory system? In a shared memory system, processors are connected via an interconnection network, so that every core can access ach memory location. And there are different hardware structures in implementing this idea. In shared-memory system all processors are either connected directly to the main memory or have their own memory blocks and are accessible to each other through special hardware build into the processors. Anyway, shared memory parallel computers may have different implementations, but generally have in common the ability for all processors to access all memory as global address space, which means multiple processors can operate independently but share the same memory resources. Furthermore, changes in a memory location operated by one processor are visible to all other processors. Interconnection topologies Thus, the first type of system is called a uniform memory access, or UMA, system, while the second type is called a nonuniform memory access, or NUMA, system. In UMA systems the time for every core to access the memory locations is the same, while in NUMA access time from one cache to distributed data parts varies as topology place. The NUMA Systems In a Nonuniform Memory Access architecture, each CPU has a memory module physically next to it, Advantages: Global address space provides a user-friendly programming perspective to memory Data sharing between tasks is both fast and uniform due to the proximity of memory to CPUs Disadvantages: Primary disadvantage is the lack of scalability between memory and CPUs. Programmer responsibility for synchronization constructs that ensure “correct” access of global memory. Interconnection networks This is important in implementing hardware of shared-memory parallelism: the efficiency of data exchange between memory and processors have huge impact on final execution time. Shared-memory interconnects Here we will explain two most widely used interconnects in shared-memory systems: buses and crossbars. The key property for a bus is that the devices connected to it share the communication wires. Since the amount of our cores is not many, it is more flexible to use a bus. However, the expected performance decreases as the number of cores connected to the bus increases. Thus, buses are replaced by switched interconnects in a more complicated shared-memory system. As name suggests, switched interconnects use switches to control the data among the connected devices. (Figure of crossbars) The individual switches can be shown as one from following figure (Figure of crossbar status) Crossbar switches are too expensive for large -scale systems, but are useful in some small systems. However, we can simplify the idea, that leads us to Omega (or Delta) Interconnects, which is similar to crossbars, but with fewer paths. (Figure of Omega Interconnects) Cache Issues Before we go further on this topic, let us firstly recall the idea of caching. To solve the problem of redundant time of processors accessing data in main memory we added block of Cache Coherency Explanation: To understand these issues, suppose we have a shared-memory system with two cores, each of which has its own private data cache. As long as the two cores only read share data, there is no problem. For example, suppose that x is a shared variable that has been initialized to value 3. In one cache we have the instruction that changes the value of x to 7, while in another cache at the same time also have operation concerning the value of x, which leads to the problem of 3 or 7? (could be a figure involving things describes above) However, this will be unpredictable situation when situations mentioned above occur regardless of whether the system using which policy among processors, because this occurs in caches with in ","date":"2020-06-07","objectID":"/posts/seminar-hpc/shared-memory-parallelism_2/:1:2","tags":["parallel computing","Seminar-HPC"],"title":"当我们谈论 shared memory parallelism 的时候我们在谈论些什么--提升篇","uri":"/posts/seminar-hpc/shared-memory-parallelism_2/"},{"categories":["学习笔记"],"content":"3. OpenMP is an API designed for programming shared-memory parallel programming. The MP in OpenMP stands for “multiprocessing”. Something good about OpenMP is that the programmer does not need to specify how each thread behave explicitly, which suggests that OpenMP allows the programmer to simply mark that the block of code should be executed in parallel, and the exact determination of which thread should execute them is handed to the compiler and the run-time system. In other word, OpenMP requires more compiler support rather works like a library of functions. This convenience in writing parallel program does not come at no cost: we give away the power to program virtually any possible thread behaviour in exchange. (give an example of a program in OpenMP, then introduce the basic rules of writing program with OpenMP) ","date":"2020-06-07","objectID":"/posts/seminar-hpc/shared-memory-parallelism_2/:1:3","tags":["parallel computing","Seminar-HPC"],"title":"当我们谈论 shared memory parallelism 的时候我们在谈论些什么--提升篇","uri":"/posts/seminar-hpc/shared-memory-parallelism_2/"},{"categories":["学习笔记"],"content":"4.Usage in high performance computing Parallelism not always make the execution faster, sometimes the more parallelism we had, the slower the program ran, which means we need to reconsider the task before we choose to implement it parallelly. ​ (table with run time of Dijkstra with 1000 nodes but different number of threads) ​ (table with run time of Dijkstra with 25000 nodes but different number of threads) Possible way to improve our performance when writing parallel program with OpenMP on shared-memory systems: False sharing could be a problem. Example to this: analysis the execution of a Matrix multiplies a vector. $Y = A * x$ #pragma omp parallel for num_threads(thread_count) \\ default(none) private (i, j) shared(A, x, y, m, n) for(i =0; i\u003c m; i++){ y[i] = 0.0; for(j = 0; j \u003c n; j++){ y[i] += A[i][j] * x[j]; } } We will compare the performance of the matrix 8000000 x8 or 8000000 x 8 or 8 x 8000000 (efficiency table here) Although we may face much larger numbers in high performance computing Why is multi threads worse than less threads? Suppose for the moment that threads 0 and 1 are assigned to one of the processors and threads 2 and 3 are assigned to the other. Also suppose that for the 8x8,000,000 problem all of y is stored in a single cache line. Then every write to some element of y will invalidate the line in the other processor’s cache. For example, each time thread 0 updates y[0] in the statement. $y[i] += A[i][j] * x[j];$ if thread 2 or 3 is executing this code, it will have to reload y. Each thread will update each of its components 8,000,000 times. We see that with this assignment of threads to processors and components of y to cache lines, all the threads will have to reload y many times. This is going to happen in spite of the fact that only one thread accesses any one component of y, for example, only thread0 accesses $y[0]$. (Explain why false sharing may not be a problem here) Possible ways of avoiding false sharing in the matrix multiplication program: One possible solution is to “pad” y vector with dummy elements in order to guarantee that any update by one thread won’t influence another cache line. Another alternative way is to have its own private storage during the loop, and then update the shared storage when iterations are done. ","date":"2020-06-07","objectID":"/posts/seminar-hpc/shared-memory-parallelism_2/:1:4","tags":["parallel computing","Seminar-HPC"],"title":"当我们谈论 shared memory parallelism 的时候我们在谈论些什么--提升篇","uri":"/posts/seminar-hpc/shared-memory-parallelism_2/"},{"categories":["学习笔记"],"content":"computer graphics中的一个小算法","date":"2020-05-21","objectID":"/posts/computer_graphics/implementation-about-diamond-square/","tags":["real-time computer graphics"],"title":"基于diamond-square-algorithm生成高度图的C++实现","uri":"/posts/computer_graphics/implementation-about-diamond-square/"},{"categories":["学习笔记"],"content":"其实很多时候我们看到的这些渲染真的是很神奇的事，比如一些terrain看似是三维的，其实可以由二维产生，即为每一个像素点赋予一个高度值，这些高度值构成的点列又可以转换为一张二维图像来存储，需要的时候，相应的地形可以由此图片生成。淡淡的想，一些所谓的空间法术，大概也就是这样了吧。高度图作为维度空间法术的入门想来也是极好的。 至于法术的入门，我们只关注用正态分布或diamond square来赋值，terrain generator中关于color和normal的值图像我们后面会聊到。 下面来看代码： #include \u003ciostream\u003e#include \u003ctchar.h\u003e#include \u003cwinnt.rh\u003e #include \u003csstream\u003e#include \u003crandom\u003e #include \u003cSimpleImage.h\u003e#include \u003cTextureGenerator.h\u003e#include \u003ctime.h\u003e #include \u003cvector\u003e //#pragma comment(lib, \"GEDUtilsd.lib\") //Declare functions float squareStep(float* field, int x, int y, int reach, int width); float diamondStep(float* field, int x, int y, int reach, int width); float random(float min, float max); //GEDUtils::SimpleImage transfer(float* field, int width); void smoothArray(float* field, int64_t width, int64_t height); void diamondSquare(float* field, int size, int width, float roughness); using namespace std; // Define a macro for easier access to a flattened 2D array #define IDX(x, y, w) ((x) + (y) * (w)) //Define the size of an array #define ARR_LEN(array, length){length = sizeof(array)/sizeof(array[0]);} /* int main() { std::cout \u003c\u003c \"Hello World!\\n\"; } */ //use for debugging void printArray(float* field, uint64_t width, uint64_t height) { for (uint64_t y = 0; y \u003c height; y++) { for (uint64_t x = 0; x \u003c width; x++) std::cout \u003c\u003c field[IDX(x, y, width)] \u003c\u003c \" \"; std::cout \u003c\u003c std::endl; } } int _tmain(int argc, _TCHAR* argv[]) { //int len; /* ARR_LEN(argv, len); if (argc != len) { throw \"invalid length\"; } */ cout \u003c\u003c endl \u003c\u003c \"argc = \" \u003c\u003c argc \u003c\u003c endl; cout \u003c\u003c \"Command line arguments received are:\" \u003c\u003c endl; for (int i = 0; i \u003c argc; i++) cout \u003c\u003c \"argument \" \u003c\u003c (i + 1) \u003c\u003c \": \" \u003c\u003c argv[i] \u003c\u003c endl; if (_tcscmp(argv[1], TEXT(\"-r\")) != 0 || _tcscmp(argv[3], TEXT(\"-o_height\")) != 0 || _tcscmp(argv[5], TEXT(\"-o_color\")) != 0 || _tcscmp(argv[7], TEXT(\"-o_normal\")) != 0) { throw \"do not match '-r' or '-o's\"; } //alternative way for resolution //std::wstringstream wsstream; //wsstream \u003c\u003c argv[2]; //int resolution; //wsstream \u003e\u003e resolution; int resolution = _tstoi(argv[2]); if (resolution \u003c= 0) { throw \"\u003c= 0 for resolution\"; } //preparation for normal mapping std::default_random_engine e; std::normal_distribution\u003cfloat\u003e n(0, 1); int length = resolution * resolution; float* field = new float[length]; //mapping normal distribution for (int y = 0; y \u003c resolution; y++) { for (int x = 0; x \u003c resolution; x++) { float value = n(e); while (value \u003c 0.0f || value \u003e 1.0f) { value = n(e); } field[IDX(x, y, resolution)] = value \u003e= 0 ? value : -value; } } //name of height file wstring wsh(argv[4]); const wchar_t* cstrh = wsh.c_str(); //name of color file wstring wsc(argv[6]); const wchar_t* cstrc = wsc.c_str(); //name of normal file wstring wsn(argv[8]); const wchar_t* cstrn = wsn.c_str(); //generate a texture generator GEDUtils::TextureGenerator texGen(L\"..\\\\..\\\\..\\\\..\\\\external\\\\textures\\\\gras15.jpg\", L\"..\\\\..\\\\..\\\\..\\\\external\\\\textures\\\\ground02.jpg\", L\"..\\\\..\\\\..\\\\..\\\\external/textures/kork02.jpg\", L\"..\\\\..\\\\..\\\\..\\\\external\\\\textures\\\\rock1.jpg\"); try { //this is for normal distribution /* //copy the created normal distribution values to the heightfield GEDUtils::SimpleImage heightImage = GEDUtils::SimpleImage::SimpleImage((UINT)resolution, (UINT)resolution); for (int y = 0; y \u003c resolution; y++) { for (int x = 0; x \u003c resolution; x++) { heightImage.setPixel(x, y, field[IDX(x, y, resolution)]); } } //save the generated heightField if (!heightImage.save(cstrh)) { throw \"Could not save heightField image\"; } // Load height image into the image test //GEDUtils::SimpleImage test(cstrh); //create a vector to store vector\u003cfloat\u003e vectorHeight(field, field + length); //this is for normal distribution //texGen.generateAndStoreImages(vectorHeight,resolution - 1,cstrc,cstrn); delete[] field; */ //this is for diamond square int length2 = (resolution + 1) * (resolution + 1); float* field2 = new float[length2]; //assign random value to the corners field2[IDX(0, 0, resolution + 1)] = random(0, 1); field2[I","date":"2020-05-21","objectID":"/posts/computer_graphics/implementation-about-diamond-square/:0:0","tags":["real-time computer graphics"],"title":"基于diamond-square-algorithm生成高度图的C++实现","uri":"/posts/computer_graphics/implementation-about-diamond-square/"},{"categories":["学习笔记"],"content":"有穷自动机笔记2","date":"2020-05-14","objectID":"/posts/theo/something-about-dfa-and-nfa-2/","tags":["theory of computation","theoretical computer science"],"title":"DFA与NFA的故事(二)","uri":"/posts/theo/something-about-dfa-and-nfa-2/"},{"categories":["学习笔记"],"content":"我们从(一)可以认识到DFA和NFA是什么样子的，并且知道它们之间的等价性，在“从有穷自动机到正则语言”一篇中我们知道DFA，NFA和正则表达式及正则语言中的等价性，同时还有一些工具如泵引理和Ardens Lemma来对它们或证明或转换。目前我们在‘术’的层面有一些进展，不妨也在或‘道’或‘术’的层面深入一些。 不妨去想一想为什么会要有穷自动机和正则语言？它们又可以用来干些什么呢？ 用Tobias教授的话来说，是一个 “Entscheidungsverfahren”, 也就是一种“判断过程”，对于已有的这些有穷自动机或是正则表达式，如何判断它们是否具备某一个属性X呢？这么说或许还是太抽象了，我们用具体的问题来说：如果有一个 D ，D是一个DFA 或是 NFA 或是 RE 或是 rechtlineare Grammatik …, 要判断如下问题： Wortproblem: 判断一个词是否被D所接受识别；Leerheitproblem： D接受的语言是否是空集；Endlichkeitsproblem： D所产生的语言是有限的还是无限的；Äquivalenzproblem: 对于 D1 和 D2 它们是否等价。那么如何判断这些问题是可判断的呢，这也就涉及到理论计算机比较核心的内容了：如果有一个算法可以在有限时间内给出正确的输出，那么就是可判断的。 现在不妨看看上述四种问题的具体判断： Lemma 3.36 Das Wortproblem ist für ein Wort w und DFA M in Zeit O(|w| + |M|) entscheidbar. Lemma 3.37 Das Wortproblem ist für ein Wort w und NFA N in Zeit O($|Q|^2$|w| + |N|) entscheidbar. Beweis： Sei Q = {1, … ,s}, $q_0 = 1 und w = a_1 … a_n$. S:= {1} for i := 1 to n do S:= $\\cup _{j \\in S} \\delta (j, a_i)$ return ($S \\cap F \\neq \\emptyset$) Lemma 3.38 Das Leerheitsproblem ist für DFAs und NFAs entscheidbar (in Zeit O(|Q||$\\Sigma$|) bzw. O($|Q|^2 |\\Sigma|$)). Beweis: L(M) = $\\emptyset$ gdw kein Endzustand von $q_0$ erreichbar ist. Dies ist eine einfache Suche in einem Graphen, die jede Kante maximal ein Mal benutzen muss. Ein NFA hat $\\leq |Q|^2|\\Sigma|$ Kanten, ein DFA hat $\\leq |Q||\\Sigma|$ Kanten. Ist $\\Sigma$ fix, z.B. ASCII, so wird daraus O($|Q|^2$) bzw O(|Q|). Lemma 3.39 ","date":"2020-05-14","objectID":"/posts/theo/something-about-dfa-and-nfa-2/:0:0","tags":["theory of computation","theoretical computer science"],"title":"DFA与NFA的故事(二)","uri":"/posts/theo/something-about-dfa-and-nfa-2/"},{"categories":["学习笔记"],"content":"数据链路层介绍","date":"2020-05-12","objectID":"/posts/computernetwork/data-link-layer/","tags":["computer network"],"title":"功能重要单一的数据链路层","uri":"/posts/computernetwork/data-link-layer/"},{"categories":["学习笔记"],"content":"连接的特征（Verbindungscharakterisierung） 两个节点之间的连接会有如下的各种属性：传输速率（Übertragungsrate），传输延迟（Übertragungsverzögerung），传输方向（Übertragungsrichtung），以及多路访问或多路复用（Mehrfachzugriff (Multiplexing)）。 ","date":"2020-05-12","objectID":"/posts/computernetwork/data-link-layer/:1:0","tags":["computer network"],"title":"功能重要单一的数据链路层","uri":"/posts/computernetwork/data-link-layer/"},{"categories":["学习笔记"],"content":"点对点的信道 Übertragungsrate 数据在信道上面被放置的时间我们称作Serialisierungszeit，记作 $t_s$, L 为需要传输的数据大小，r 为传输速率，于是 $$ t_s = \\frac{L}{r} $$ 这里的$t_s$可以认为是传输时延，传输这些数据会要用到的时间。 Ausbreitungsverzögerung 顾名思义，传播延迟，与上面的不一样的是这是信号在信道中从一段到另一端会花的时间： $$ t_p = \\frac{d}{vc_0} $$ $c_0$即为光速，v为一个常数， 与传输介质有关。 Gesamtverzögerung $t_d 即是总的延迟为上面两项的和$。 Bandbreitenverzögerungsprodukt 这个就是所谓的宽带延迟，正是因为在信道中的传播不可避免的需要时间，我们需要一定容量来存储： $$ C = t_p r = \\frac{d}{vc_0} r $$ 单位是bit。 Übertragungsrichtung Übertragungsrichtung ","date":"2020-05-12","objectID":"/posts/computernetwork/data-link-layer/:1:1","tags":["computer network"],"title":"功能重要单一的数据链路层","uri":"/posts/computernetwork/data-link-layer/"},{"categories":["学习笔记"],"content":"广播信道的数据链路层 一般来说这里我们会用到时分复用（Zeitmultiplex），即用一个信道实现不同端口之间的通信，基于分组网络（以太网，无线局域网）中的非确定性方法（并发访问）。 至于复用我想教授的slide上面的图已经很清楚了： Multiplexing ALOHA and Sorted ALOHA CSMA, CSMA/CD, CSMA/CA CSMA 指的其实是 Carrier Sense Multiple Access, 是对于前面sorted ALOHA的一种简单的优化，也即“listen before talk”。 CSMA/CD 中文翻译也即 载波监听碰撞监听多点接入/碰撞检测，以太网即用此协议，分为载波监听和碰撞检测两部分：即“发送前先监听”，每个站在发送数据前要先检测一下总线上是否有其他站在发送数据，如果有，暂时不发送数据，等待信道空闲时再发送，总线上没有“载波”，这里只是一个习惯称呼；-碰撞检测：即“边发送边监听”，适配器边发送数据边检测信道上的信号电压，以便判断自己在发送数据时其他站是否也在发送数据。同时发送数据时，总线上的信号电压变化幅度大，超过一定门限值时，就认为总线上至少两个站同时在发送数据，表明有碰撞。这时总线上的信号失真，无法恢复。所以，每一个正在发送数据的站，一旦发现有碰撞，适配器就要立即停止发送，以免浪费网络资源，等待一段随机时间后再发送。 如果考虑上信号在链路上的传播时延，那么过程类似这样； CSMA/CD 每个端点在自己发送数据之后的一小短时间内，存在着遭遇碰撞的可能性，这段时间最长为两个单程最长时间，将这个时间成为“争用期”，只有通过争用期的“考验”，才能肯定这次发送不会发生碰撞。正是因为这个原因，以太网规定了数据帧的最小长度即64字节，所有小于此长度都认为是碰撞导致的丢弃帧。当我们接收到至少64字节我们就可认为这之间没有碰撞。 CSMA/CD不能同时进行发送和接受，因此是Halbdulplex，也就是半双工协议，即双向交替通信。 CSMA/CA 在有线连接的局域网中就不能使用CSMA/CD（无线局域网中），因为即使发送的信息足够长, 也不能总是检测到碰撞。这里的CA其实就是colision avoidance，发送包的同时不能检测到信道上有无冲突，只能尽量“避免”。例如，如果计算机A和计算机C同时给计算机B发送一个控制消息，它们将同时到达计算机B，导致冲突的发生。当这种冲突发生时，发送者可以随机等待一段时间，然后重发控制消息。因为控制消息比数据帧要短得多，所以发生第二次冲突的可能性也要比传统以太网要小很多。最终将有一个控制消息正确到达，然后计算机B发送一个响应消息。通常CSMA/CA利用ACK信号来避免冲突的发生，也就是说，只有当客户端收到网络上返回的ACK信号后才确认送出的数据已经正确到达目的。 教授slide中是这样说的： Wenn Medium frei, übertrage mit Wahrscheinlichkeit p oder verzögere mit Wahrscheinlichkeit 1 − p um eine feste Zeit dann 1. Wenn Medium belegt, warte bis frei, dann 1. ","date":"2020-05-12","objectID":"/posts/computernetwork/data-link-layer/:1:2","tags":["computer network"],"title":"功能重要单一的数据链路层","uri":"/posts/computernetwork/data-link-layer/"},{"categories":["学习笔记"],"content":"封装成帧 封装简单说就是事先对数据包进行拆分和打包，在所发送的数据包上附加上目标地址，本地地址，以及一些用于纠错的字节等。对数据包进行处理时通信双方所遵循和协商好的规则就是协议。 网络层传输的包（packet）在数据链路层中传输的是帧就（frame，Rahmen）。数据包到达数据链路层后加上数据链路层的协议头和协议尾就构成了一个数据帧。 ","date":"2020-05-12","objectID":"/posts/computernetwork/data-link-layer/:2:0","tags":["computer network"],"title":"功能重要单一的数据链路层","uri":"/posts/computernetwork/data-link-layer/"},{"categories":["学习笔记"],"content":"MAC地址 是指局域网上的每一台计算机中固化在适配器的ROM中的地址（因此也叫适配器地址或适配器标识符EUI—48），由硬件厂商决定，是不会变的。只要适配器不变，它就不变。它是每一个站的“名字”或标识符。如果连接在局域网上的主机或路由器安装有多个适配器，那么这样的主机或路由器就有多个“地址”，也就是说，这种48位地址应当是某个接口的标识符。当然通过相应软件也是可以改变mac地址的。 MAC帧格式 ","date":"2020-05-12","objectID":"/posts/computernetwork/data-link-layer/:2:1","tags":["computer network"],"title":"功能重要单一的数据链路层","uri":"/posts/computernetwork/data-link-layer/"},{"categories":["学习笔记"],"content":"差错检测 ","date":"2020-05-12","objectID":"/posts/computernetwork/data-link-layer/:3:0","tags":["computer network"],"title":"功能重要单一的数据链路层","uri":"/posts/computernetwork/data-link-layer/"},{"categories":["学习笔记"],"content":"CRC亢余检测 ","date":"2020-05-12","objectID":"/posts/computernetwork/data-link-layer/:3:1","tags":["computer network"],"title":"功能重要单一的数据链路层","uri":"/posts/computernetwork/data-link-layer/"},{"categories":["学习笔记"],"content":"有穷自动机中的部分java实现","date":"2020-05-12","objectID":"/posts/theo/something-about-regular-expression-implementation/","tags":["theory of computation","theoretical computer science"],"title":"从有穷自动机到正则语言---实现篇","uri":"/posts/theo/something-about-regular-expression-implementation/"},{"categories":["学习笔记"],"content":"本篇可以看作是“从有穷自动机到正则表达式”此篇的番外篇，主要是提供JAVA实现从DFA到RE的转换。因为代码完全是从作业中copy的，不知道会不会有版权问题，但这也不算商业用途，其中有一部分代码也是我自己写的，所以应该问题不大吧。（作业默认会给出Java和Haskell的一些源码，我不太想写Haskell所以就用Java来实现了，有兴趣的可以自己从copy代码后试一试） 先来看看正则表达式的实现，其中有一个Regex的抽象类，和另一篇博文中关于正则表达式的定义相对应，有6个子类来作为归纳的基础，分别是$\\epsilon , \\emptyset$, 单个字母，连接，并，星号，下面是代码。 import java.util.Arrays; import java.util.Collections; import java.util.HashMap; import java.util.HashSet; import java.util.Iterator; import java.util.LinkedList; import java.util.List; import java.util.Map; import java.util.Set; import java.util.stream.Stream; public abstract class Regex { /** * Determines whether the given string matches the regular expression. * @param word the string * @return */ public abstract boolean matches(String word); private static final class ReadOnlyIterator\u003cT\u003e implements Iterator\u003cT\u003e { private final Iterator\u003cT\u003e it; public ReadOnlyIterator(Iterator\u003cT\u003e it) { this.it = it; } @Override public boolean hasNext() { return it.hasNext(); } @Override public T next() { return it.next(); } } public static final class Empty extends Regex { @Override public boolean matches(String word) { return false; } @Override protected void appendTo(StringBuilder sb, int prec) { sb.append(\"{}\"); } private Empty() { } @Override protected int getPrecedence() { return 4; } @Override public int hashCode() { return 23; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; return (getClass() == obj.getClass()); } public int size() { return 1; } @Override public boolean isNullable() { return false; } @Override public \u003cR\u003e R accept(Visitor\u003cR\u003e vis) { return vis.visitEmpty(); } } public static final class Epsilon extends Regex { @Override public boolean matches(String word) { return word.isEmpty(); } private Epsilon() { } @Override protected void appendTo(StringBuilder sb, int prec) { sb.append(\"()\"); } @Override protected int getPrecedence() { return 4; } @Override public int hashCode() { return 47; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; return (getClass() == obj.getClass()); } public int size() { return 1; } @Override public boolean isNullable() { return true; } @Override public \u003cR\u003e R accept(Visitor\u003cR\u003e vis) { return vis.visitEpsilon(); } } public static final class Single extends Regex { private final char c; @Override public boolean matches(String word) { return word.length() == 1 \u0026\u0026 word.charAt(0) == c; } @Override protected int getPrecedence() { return 4; } public char getChar() { return c; } private Single(char c) { super(); this.c = c; } @Override protected void appendTo(StringBuilder sb, int prec) { sb.append(c); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + c; return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; Single other = (Single) obj; if (c != other.c) return false; return true; } public int size() { return 1; } @Override public boolean isNullable() { return false; } @Override public \u003cR\u003e R accept(Visitor\u003cR\u003e vis) { return vis.visitSingle(c); } } public static final class Concat extends Regex implements Iterable\u003cRegex\u003e { private final List\u003cRegex\u003e children; private final int size; private final boolean nullable; private Concat(List\u003cRegex\u003e children) { super(); List\u003cRegex\u003e children2 = new LinkedList\u003c\u003e(); int size = 1; boolean nullable = true; for (Regex r : children) { if (r instanceof Epsilon) continue; children2.add(r); size += r.size(); nullable = nullable \u0026\u0026 r.isNullable(); } this.size = size; this.nullable = nullable; this.children = Collections.unmodifiableList(children2); } @Override public boolean matches(String word) { for (int i = 0; i \u003c= word.length(); ++i) { Regex concatRest = Regex.epsilon().concat(children.subList(1, children.size())); if (children.get(0).matches(word.substring(0, i)) \u0026\u0026 concatRest.matches(word.substring(i)) )","date":"2020-05-12","objectID":"/posts/theo/something-about-regular-expression-implementation/:0:0","tags":["theory of computation","theoretical computer science"],"title":"从有穷自动机到正则语言---实现篇","uri":"/posts/theo/something-about-regular-expression-implementation/"},{"categories":["学习笔记"],"content":"初识高性能计算","date":"2020-05-03","objectID":"/posts/seminar-hpc/shared-memory-parallelism_1/","tags":["parallel computing","Seminar-HPC"],"title":"当我们谈论 shared memory parallelism 的时候我们在谈论些什么--前导篇","uri":"/posts/seminar-hpc/shared-memory-parallelism_1/"},{"categories":["学习笔记"],"content":"在目前正在更的Theo和Network系列上又要开启新的系列了呢，也就是目前看到的 parallel computing 系列。因为这个学期刚好选到一个主题是high performance computing (HPC) 的Seminar，然后自己被分配到的题目就是标题所说的\"shared memory parallelization\"。因为最后需要交一篇paper还要做一个presentation，觉得也可以新开一个系列来整理记录自己看各种资料时候学习到的相关的新知识，当然因为看的资料本身是英语，为了之后写paper方便我有些时候也就直接写英语了。本篇主要内容是最近要交的outline和一些关于并行计算的导引。 General concept why parallel? what is the idea of shared memory? memory modules Hardware views Different architecture UMA Systems Pro Nach NUMA Systems Pro Nach How do interconnection networks work? basic ideas that distiguish from normal networks switch, crossbar…. Cache issues Cache coherence: Snooping cache coherence Directory-based cache coherence False sharing: Basic explanaton, will have further discussion in programmer’s view Programmer’s view parallel programming models shard memory without threads threads model: some basic concept and implementation with OpenMP or CUDA some example parallel programs written in OpenMP that may concerning to solving flase sharing Difference in HPC Distiguish what’s special about shared memory in HPC (still not quite clear, need further readings) Materials related: Prgramming on Parallel Machines, Norm Matloff, Univercity of California, Davis An Introduction to Parallel Programming, Peter Pacheco Parallel Computer Architecture A Hardware / Software Approach, David Culler, Jaswinder Paul Singh Parallel Programming for Modern High Performance Computing Systems, Paul Czarnul Slide of an old lecture from TUM: https://www5.in.tum.de/lehre/vorlesungen/parhpp/SS08/ ","date":"2020-05-03","objectID":"/posts/seminar-hpc/shared-memory-parallelism_1/:0:0","tags":["parallel computing","Seminar-HPC"],"title":"当我们谈论 shared memory parallelism 的时候我们在谈论些什么--前导篇","uri":"/posts/seminar-hpc/shared-memory-parallelism_1/"},{"categories":["学习笔记"],"content":"正则语言笔记","date":"2020-05-03","objectID":"/posts/theo/something-about-regular-language/","tags":["theory of computation","theoretical computer science"],"title":"从有穷自动机到正则语言","uri":"/posts/theo/something-about-regular-language/"},{"categories":["学习笔记"],"content":"在上篇中我们了解到DFA与NFA的故事，从中我们初识了正则运算并且了解到其封闭性(虽然我还没有写完)，在本篇中我们将会里了解到正则表达式，进而到正则语言，我们可以从这个小小的角度对归纳的魅力有惊鸿一瞥，还可以了解到有穷自动机，正则表达式，正则语言它们之间的转换。 ","date":"2020-05-03","objectID":"/posts/theo/something-about-regular-language/:0:0","tags":["theory of computation","theoretical computer science"],"title":"从有穷自动机到正则语言","uri":"/posts/theo/something-about-regular-language/"},{"categories":["学习笔记"],"content":"正则表达式及形式化定义 正则表达式其实是正则语言(formal language)的另一种定义。 我们不妨来看看定义，这里其实就可以就感受到归纳的威力了！ R是正则表达式(RE)当且仅当R是 a, $a \\in \\Sigma$; /表示 {a}/ $\\epsilon$ /表示 ${\\epsilon}$/ $\\emptyset$ $(R_1 \\cup R_2)，R_1和 R_2都是正则表达式；$ $(R_1 R_2), R_1和R_2都是正则表达式；$ $(R_1^ *)，R_1是正则表达式.$ L(R): R表示的语言 ","date":"2020-05-03","objectID":"/posts/theo/something-about-regular-language/:0:1","tags":["theory of computation","theoretical computer science"],"title":"从有穷自动机到正则语言","uri":"/posts/theo/something-about-regular-language/"},{"categories":["学习笔记"],"content":"正则语言封闭性 有空再写吧，本质还是构造法 ","date":"2020-05-03","objectID":"/posts/theo/something-about-regular-language/:0:2","tags":["theory of computation","theoretical computer science"],"title":"从有穷自动机到正则语言","uri":"/posts/theo/something-about-regular-language/"},{"categories":["学习笔记"],"content":"正则表达式与有穷自动机的等价性 我们已经知道有穷自动机识别的语言是正则语言，而后我们又认识到正则表达式(regular expression，RE)也可以来定义语言，他们两者的关系是怎样的呢？下面我们就来证明正则表达和有穷自动机是等价的。 等价，参考上一篇文章也就是说他们能够描述同样的语言。 我们要证明的也就是以下定理： Satz 3.19 (Kleene 1956) Eine Sprache L $\\in$ $\\Sigma^{*}$ ist genau dann durch einen regulären Ausdruck darstellbar, wenn sie regulär ist. 这也其实就是要我们证明：一个语言是正则的当且仅当可用正则表达式描述这个语言。 我们要做的其实也就是有一个正则表达式，我们要构造一个有穷自动机识别正则表达式产生的那些串；然后给定一个自动机，我们要构造一个正则表达式使得这个RE描述的串正好是自动机识别的串，所以我们要给定一个算法能在有穷自动机和相应的RE之间进行转换，并且这种转换是等价的。 先来看看 “$\\implies$” 方向： 这里需要做的其实是就是构造一个有穷自动机去识别相应的语言，也就是将一个正则表达式转换为自动机。关于自动机其实为了方便只需要关注NFA就可以了，因为上一篇文章中我们已经证明了DFA和NFA的等价性。 正则表达式是通过前文说的6个基本步骤来定义的，前三个是基本步骤，后三个是归纳步骤；我们只需说明对于每一个步骤如何去构造相应的有穷自动机即可完成证明。 R = a, a$\\in\\Sigma$. L(R) = {a}, N = ({$q_1$, $q_2$ }, $\\Sigma$, $\\delta$, $q_1$, {$q_2$} ), $\\delta (q_1, a)$ = ${q_2 }$, $\\delta (r, b) = \\emptyset$, 若$r\\neq q_1$或$b \\neq a$ (其实就是只有a的语言) R = $\\epsilon$. L(R) = {$\\epsilon$}, N = ( {$ q_1 $}, $\\Sigma, \\delta, q_1$, {$q_1$} ), $\\forall r, \\forall b, \\delta (r, b) = \\emptyset$. (只有一个状态$q_1$接受空串，其他串都不接受) R = $\\emptyset$. L(R) = $\\emptyset$, N = ( {$q_1 $}, $\\Sigma , \\delta , q_1, \\emptyset$), $\\forall r, \\forall b, \\delta(r,b)=\\emptyset$. (只有一个状态$q_1$，但区别不是接受状态，也即什么串也不接受) $R=(R_1 \\cup R_2)$, 这里直接上教授slides上面的图 并/alternative 这个新自动机的接受状态为原来接收状态的并，并且用一个新的初始状态来代替旧的。 $R=(R_1 R_2)$, 这里还是看图说话 连接/concatenation 这个新自动机接受状态为后一个的接受状态，而初始状态只有第一个的了。 $ R =(R_1 ^*)$, 还是直接给出图比较直观 星号/star 加入一个新的初始状态，并且本身是一个接收状态，这样可以保证接受$\\epsilon$空串，然后通过$\\epsilon$连接新旧初始状态，和接受状态。 这一个方向证毕。 再来看看 “$\\Longleftarrow$” 方向： 这里其实有两种证明方式，一种是通过定于广义非确定型有穷自动机来证明，还有一种是Tobia教授课上给出的一种算法，我们不妨都来学习学习。 先来看看Tobias教授给出的算法： Sei $M = (Q, \\Sigma ,\\delta , q_1 , F) ein DFA$. (Funktioniret analog auch für NFA) WIr konstruieren einen RE $\\gamma$ mit L(M) = L ($\\gamma $). Sei Q = {$q_1 ,…,q_n$}.Wir setzen $$ R_{ij}^{k}:= \\lbrace w \\in \\Sigma ^* | die \\ Eingabe\\ w \\ führt\\ von\\ q_i\\ in\\ q_j ,wobei\\ alle Zwischenzustände (ohne\\ ersten\\ und\\ letzten) einen\\ Index\\ \\leq k\\ haben\\ \\rbrace $$ Behauptung: Für alle $i, j \\in \\lbrace1,…,n\\rbrace und\\ k \\in \\lbrace 0,…,n \\rbrace können\\ wir\\ einen\\ RE\\ L(\\alpha {ij}^k) = R{ij}^k$ Induktion über k: k = 0: Hier gilt 再来看看另一种证法： 其实也就是定义一个广义非确定型有穷自动机（GNFA），从DFA构造等价的GFNA，从GFNA构造等价的正则表达式。 GFNA的特殊在于状态间的转移不 ","date":"2020-05-03","objectID":"/posts/theo/something-about-regular-language/:0:3","tags":["theory of computation","theoretical computer science"],"title":"从有穷自动机到正则语言","uri":"/posts/theo/something-about-regular-language/"},{"categories":["学习笔记"],"content":"泵引理 泵引理（Pumping Lemma für reguläre Sprachen），用来证明一个语言不是正则的神奇工具。有些语言看起来很规则，但是却不是正则语言，因为无法用有穷自动机来描述，我们用泵引理即可很有效地判断不是正则语言的情况，但却无法证明是正则语言，因为只是必要条件而不是充分条件。下面来看看泵引理具体长什么样子，既有中文版，也有德语版： 泵引理：设A是正则语言，则存在常数p（称为泵长度），使得若 s $\\in$ A且 |s| $\\geq$，则 s = xyz，并且满足下述条件： $\\forall i \\geq 0, xy^iz \\in A;$ |y| \u003e 0; |xy| $\\leq p$. 这里第一个条件其实很有意思，这其实很像前面广义非确定有穷自动消除一个顶点后出来的表达式，实际上并不是巧合，从某个状态出发读了x之后进入一个状态，这个状态自己到自己有一个箭头，并且可以通过 y 来到达，这个状态读取 z后到接受状态（这个样子其实和水泵也很像）。 接下来看看德语版： Satz 3.30 (Pumping Lemma für reguläre Sprachen) Sei R $\\subseteq \\Sigma ^*$ regulär. Dann gibt es ein n \u003e 0, so dass sich jedes z $\\in$ R mit |z| $\\geq$ n so in $z = uvw$ zerlegen lässt, dass $v \\neq \\epsilon$ $|uv| \\leq n$, und $\\forall i \\geq 0. uv^iw \\in R$. 泵引理来证明语言不是正则的其实就是要来用上面的条件来推矛盾，有时候就需要灵感来取一个特殊的s，经过泵的步骤后就不在这个语言中了，就有了矛盾。 泵引理的证明 在这个证明中我们会明白如何取这个常数 p，为什么s会被分为三段，为什么xy的长度要小于等于p。 提前剧透：这里的p其实就是一个相应自动机的状态数。 证明：设A = L(M), M = (Q, $\\Sigma ，\\delta ，q_1, F$), |Q| = p, $s = s_1s_2…s_n \\in A, n \\geq p$. 设M在s上计算 $r_1,r_2,…,r_{n+1}, \\delta({r_i, s_i}) = r_{i+1}$ $r_i$为n+1个状态，经由s的n个输入字符可到达。由于总共只有p个状态，并且不超过n，而现在有n+1个状态，每一个都是Q中的元素，由著名的抽屉原理：这n+1个状态中最多只有p种不同的状态, 也就是说至少会有两个重复的状态。 根据抽屉原理，存在 j \u003c l, 使得 $r_j = r_l , l \\leq p + 1$. 令 $x = s_1 …s_{j - 1}, y=s_j …s_{l - 1}, z=s_l …s_{n+1}$. 由于$x让M从r_1 到r_j，y让M从r_j到 r_j, z让M从r_j到r_{n+1}, 而r_{n+1}是接受状态，所以\\forall i \\geq 0, xy^iz \\in A.$ 由于$j \\neq l , 所以|y|\u003e0$. 由于$l \\leq p+1, 所以|xy| \\leq p$. 这样就完成了泵引理的证明。 Tobia教授slides上面的证明也很类似： Sei R = L(A), A = ($Q, \\Sigma , \\delta , q_0 , F$). Sei n = |Q|. Sei nun z = $a_1a_2a_3…a_m \\in R$ mit m $\\geq n$. Die beim Lesen von $z$ durchlaufene Zustandfolge sei $q_0 = p_0 \\rightarrow ^{a_1} p_1 \\rightarrow ^{a_2}p_2 … \\rightarrow ^{a_m} p_m$ Dann muss es $0 \\leq i \\leq j \\leq n geben mit p_i = p_j$. Wir teilen $z$ wie folg auf: $$ \\underbrace{a_1…a_i}u\\underbrace{a{i+1}…a_j}v \\underbrace{a{j+1}…a_m}_w $$ Damit gilt: $|uv| \\leq n$ $v \\neq \\epsilon$, und $\\forall l \\geq 0 . uv^l w \\in R$ ","date":"2020-05-03","objectID":"/posts/theo/something-about-regular-language/:0:4","tags":["theory of computation","theoretical computer science"],"title":"从有穷自动机到正则语言","uri":"/posts/theo/something-about-regular-language/"},{"categories":["学习笔记"],"content":"Ardens Lemma Ardens Lemma, 也叫 Arden’s rule, 用来构造这样的自动机：只有一个初始状态，且其中没有$\\epsilon$移动。先来看看数学表达式长什么样，再来翻译翻译到底说了些啥。 $$ \\text{Sind A, B und X Sprachen mit} \\epsilon \\notin \\text{A, so gilt }\\ X = AX \\cup B \\Rightarrow X = A^B \\ \\text{其中还有一个类似的推论：} Sind\\ \\alpha , \\beta \\text{ und X regulär Ausdrücke mit } \\epsilon \\notin L(\\alpha), so\\ gilt \\ X \\equiv \\alpha X | \\beta \\Rightarrow X \\equiv \\alpha ^ \\beta $$ 于是有了这些的结论： ","date":"2020-05-03","objectID":"/posts/theo/something-about-regular-language/:0:5","tags":["theory of computation","theoretical computer science"],"title":"从有穷自动机到正则语言","uri":"/posts/theo/something-about-regular-language/"},{"categories":["学习笔记"],"content":"探索计算机网络OSI模型中的物理层的故事.","date":"2020-05-02","objectID":"/posts/computernetwork/physical-layer/","tags":["computer network"],"title":"充满机遇的物理层","uri":"/posts/computernetwork/physical-layer/"},{"categories":["学习笔记"],"content":"探索计算机网络OSI模型中的物理层的故事. 现在我们来到了计算机网络的OSI模型的第一层：物理层(physical layer)。在这里我会以教授的slides为框架简要的讨论物理层中发生的故事,主要会关注从数字信号与模拟信号之间的转化过程，这是属于离散和连续的较量呢。之所以说是充满机遇的是因为离散与连续之间有着隐藏法术等待我们去习得。 ","date":"2020-05-02","objectID":"/posts/computernetwork/physical-layer/:0:0","tags":["computer network"],"title":"充满机遇的物理层","uri":"/posts/computernetwork/physical-layer/"},{"categories":["学习笔记"],"content":"信号和信息 要想理解物理层中发生的种种有意思的事情(当然主要是数学故事啦)，还是得要有些准备工作要做的。 我们不妨看看物理层到底干了些什么： 物理层利用传输介质为通信的两端建立、管理和释放物理链接，实现比特流的透明传输，保证比特流正确的传输到对端。物理层中承载的是比特流单位是比特（bit）。我知道我已经说的这么清楚明白，你可能依然犹如漫步在云端，头重脚轻不明所以。那么我用一个生活中的例子来帮助你更好的理解。 例：比如你在和朋友聊天，说话内容需要由大脑编排好，然后将你要讲的内容送达到嘴巴，嘴巴通过发出声音让对方听到你说话的内容。并且你在讲话时也无需考虑声波会如何传送到对方的耳朵中的，并且你也看不到声波是如何传达到对方的耳朵中的。这里声波就可以理解为是‘比特流’，你的嘴巴就是提供了‘物理层’的服务。 嘴巴负责开始谈话（建立链接）、判断谈话的开始和结束（管理链接）、结束谈话（释放链接）。并且嘴巴也无需考虑声波是如何传达到对方的耳朵中，所以声波对于嘴巴是透明的。在网络中‘透明’=管理成本低。 我们知道通过信号的强弱变化可以传递出二进制编码，而这些编码被识别成不同的符号，通过这些符号也就可以传达出各种各样的信息。 在信息论中我们其实可以通过引入物理学中熵(entropy)的概念来量化信息，接收到消息中包含的信息量又称作信息熵。事实上，1948年Shannon就是这么做的，将热力学的熵引入信息学中， 于是我们可以这样来定义信息： 信息，一方面可以理解为能够预测信号变化的不确定性。于是一个字母表X中的x的信息内容取决于信息携带信号在观察时该x的出现概率，于是定义为： $$ I(x)=-\\log_{2}{p(x)} $$ 单位为bit。 信息熵于是可以由求期望的方式给出： $$ H(X)=\\sum_{x\\in X} p(x)I(x) = - \\sum_{x\\in X}p(x)\\log_{2}{p(x)} $$ ","date":"2020-05-02","objectID":"/posts/computernetwork/physical-layer/:1:0","tags":["computer network"],"title":"充满机遇的物理层","uri":"/posts/computernetwork/physical-layer/"},{"categories":["学习笔记"],"content":"信号处理（Signaldarstellung） 在物理层传输介质中传输的信号共分为两种，模拟信号、数字信号，下图给出了这两种信号的范例： 模拟限号和数字信号 由于计算机只能识别数字信号，但要在广域网中传播却又以模拟信号的形式进行(光纤的情况又有不同，这个就是后话了)，于是我们会设置一个调制解调器把数字信号转化为模拟信号以及反向的过程。 而接下来我们就来讨论这两过程的细节问题。 ","date":"2020-05-02","objectID":"/posts/computernetwork/physical-layer/:2:0","tags":["computer network"],"title":"充满机遇的物理层","uri":"/posts/computernetwork/physical-layer/"},{"categories":["学习笔记"],"content":"数学基础 开头就有说物理层的故事是属于离散和连续之间的较量，虽说离散和连续这两个相对的概念之间是只有较量，但是使用合适的方法这二者却又可以互相转换，这也就是我们要在这部分说明的神奇的数学法术。 当然如果你有足够的悟性就又可以领悟到这两个史诗级别的法术呢。 傅里叶级数（Fourier series） 在数学中，傅里叶级数能把任何周期函数或周期信号分解成一个(可能由无穷个元素组成的)简单振荡函数的集合，也即正弦和余弦函数，同时也是我们后面会说到的采样定理的核心内容。 我这里直接给出教授slides上面的定义： Ein periodisches Signal s(t) lässt sich als Summe gewichteter Sinus- und Kosinus-Schwingungen darstellen. Die so entstehende Reihenentwicklung von s(t) bezeichnet man als Fourierreihe: $$ s(t)=\\frac{a_0}{2} + \\sum_{k=1}^{\\infty} {a_k\\cos{k{\\omega}t} + b_k\\sin{k{\\omega}t}} $$ 这里的$a_0$是相对y轴的偏移量，同时$a_k$和$b_k$这两个系数可以由如下定义： $$ a_k = \\frac{2}{T}\\int_0^T {s(t)\\cos{k{\\omega}t}} {\\rm d}t $$ $$ b_k = \\frac{2}{T}\\int_0^T {s(t)\\sin{k{\\omega}t}} {\\rm d}t $$ 傅里叶变换(Fourier transform) 傅里叶变换是一种线性积分变换，用于信号在时空域和频域之间的变换。实际上借用维基百科的话来说傅里叶变换就像化学分析，确定物质的基本成分；信号来自自然界，也可以对其进行分析，确定其基本成分。 Die Fourier-Transformierte einer stetigen, integrierbaren Funktion s(t) ist gegeben als $$ s(t) \\longrightarrow S(f) = \\frac{1}{\\sqrt{2\\pi}}\\int_{t=-\\infty}^{\\infty} {s(t)(\\cos{2\\pi ft}-i\\sin{2\\pi ft})} {\\rm d}t $$ 其中$i=\\sqrt{-1}$ , 当然这里也可以写成指数形式，就不再赘述。 ","date":"2020-05-02","objectID":"/posts/computernetwork/physical-layer/:2:1","tags":["computer network"],"title":"充满机遇的物理层","uri":"/posts/computernetwork/physical-layer/"},{"categories":["学习笔记"],"content":"采样，重构和量化 有了前文的数学基础后，我们就可以开始学习信号处理过程中的采样(sampling, Abtastung)，重构(Rekonstruktion)，以及量化(Quantisierung)，从而达到让人激动的离散与连续之间的转化。更具体来说，采样(时域离散)和量化(值域离散)相结合可将模拟信号转换为数字信号，重构则可以认为是采样的逆过程。其中著名的\"Nyquist-Shannon sampling theorem\", 也即“奈奎斯特–香农采样定理”，的内容是连续信号与离散信号之间的一个基本桥梁，其实更像是对于转换的限制条件，这里在后面会更详细聊到。 采样（Abtastung） 我们这里先看看维基百科上是怎么说的： 在信号处理领域，采样是将信号从连续时间域上的模拟信号转换到离散时间域上的离散信号的过程，以采样器实现。通常采样与量化联合进行，模拟信号先由采样器按照一定时间间隔采样获得时间上离散的信号，再经模数转换器（ADC）在数值上也进行离散化，从而得到数值和时间上都离散的数字信号。 通过采样得到的信号，是连续信号（例如，现实生活中的表示压力或速度的信号）的离散形式。连续信号通常每隔一定的时间间隔被模数转换器（ADC）采样，当时时间点上的连续信号的值被表现为离散的，或量化的值。 这样得到的信号的离散形式常常给数据带来一些误差。误差主要来自于两个方面，与连续模拟信号频谱有关的采样频率，以及量化时所用的字长。采样频率指的是对连续信号采样的频度。它代表了离散信号在和时域和空间域上的精确度。字长（比特的数量）用来表示离散信号的值，它体现了信号的大小的精确性。 再来看看教授的slide上面怎么说的： Das Signal s(t) wird mittels des Einheitsimpulses (Dirac-Impulses) $\\sigma[t]$ in äquidistanten Abständen $T_a$ (Abtastintervall) für n $\\in$ Z abgetastet: $$ \\hat{x}=s(t) \\sum_{n=-\\infty}^{\\infty}\\sigma[t-nT_a]= \\begin{cases} 1, \u0026 t=nT_a \\newline 0, \u0026 sonst\\ \\end{cases} $$ Da $\\hat{s}(t)$ nur zu den Zeitpunkten nTa für ganzzahlige n von Null verschieden ist, vereinbaren wir die Schreibweise $\\hat{s}[n]$ für zeitdiskrete aber wertkontinuierliche Signale. Zeitkontinuierliches Signal und Abtastwerte 重构 在这个过程中数字信号被转换成模拟信号，就如同把采样的过程逆转一样，称作demodulation。在理想的系统上，每经过取样的固定时间而读取新的数据时，输出会即时改变到该强度。经过这样的即时转换，离散的信号本质上会有大量的高频率能量，出现与采样率的倍数相关的谐波。要消灭这些谐波并使信号流畅，信号必须通过一些模拟滤波器，压制任何在预期频域外的能量。 时域中的乘法对应于频域中的卷积： $$ s(t) \\delta [t -nT] \\rightarrow \\frac{1}{T}S(f)*\\delta[f - n/T] $$ Reconstruction 香农定理 香农定理给出了信道通信传送速率的上限和信噪比以及带宽的关系。 Abtasttheorem von Shannon und Nyquist Ein auf |f | $\\leq$ B bandbegrenztes Signal s(t) ist \u003evollständig durch äquidistante Abtastwerte ˆ s[n] beschrieben, sofern diese nicht weiter als $T_a \\leq$1/2B auseinander liegen. Die Abtastfrequenz, welche eine vollständige Signalrekonstruktion \u003eerlaubt, ist folglich durch: $$ f_a \\geq 2B $$ nach unten beschränkt. 量化 ","date":"2020-05-02","objectID":"/posts/computernetwork/physical-layer/:2:2","tags":["computer network"],"title":"充满机遇的物理层","uri":"/posts/computernetwork/physical-layer/"},{"categories":["学习笔记"],"content":"传输信道 对于无噪声，M的通道，我们会有$M = 2^N$种可区分的符号，可实现的数据率如何变化呢？ 我们先来回顾一下熵： 假设信号源以相同的概率发射所有信号，这样信号源的熵（因而平均信息）最大。 对于宽度为B的信道上的传输速率，我们可以得到最大传输速率： Harleys Gesetz $C_H = 2B \\log_{2}(M) bit$ 同时还有新的定义：信号功率（Signallesitung） 信号振幅的平方的期望值与信号功率的平方相对应。方差（分散）信号的振幅对应于不含直流分量的信号功率，并代表信息承载量信号的功率。 回到正题，不妨想想在有 ","date":"2020-05-02","objectID":"/posts/computernetwork/physical-layer/:3:0","tags":["computer network"],"title":"充满机遇的物理层","uri":"/posts/computernetwork/physical-layer/"},{"categories":["学习笔记"],"content":"有穷自动机笔记1","date":"2020-04-25","objectID":"/posts/theo/something-about-dfa-and-nfa/","tags":["theory of computation","theoretical computer science"],"title":"DFA与NFA的故事(一)","uri":"/posts/theo/something-about-dfa-and-nfa/"},{"categories":["学习笔记"],"content":"对于DFA和NFA形式定义的一些理解，以及正则运算封闭性和DFA与NFA等价性的证明，也就是说DFA的故事是属于NFA的，是特例和常规的故事呢。 ","date":"2020-04-25","objectID":"/posts/theo/something-about-dfa-and-nfa/:0:0","tags":["theory of computation","theoretical computer science"],"title":"DFA与NFA的故事(一)","uri":"/posts/theo/something-about-dfa-and-nfa/"},{"categories":["学习笔记"],"content":"对于确定型有穷自动机（DFA）的一些认识 对于确定型有穷自动机，也即deterministic finite automaton 或者说 deterministischer endlicher Automat，我们可以给出相应的形式定义，这里借用Tobias教授在课上给的定义： Ein deterministischer endlicher Automat (deterministic infinite automaton, DFA) M = (Q, ∑, δ, q0, F), besteht aus einer endlichen Menge von Zuständen Q, einem (endlichen) Eingabealphabet ∑, einer (totalen!) Übergangsfunktion δ: Q × ∑ → Q, einem Startzustand q0 ∈ Q, und einer Menge F ⊆ Q von Endzuständen (akzeptierenden Zust.) 也就是说我们首先有一个有穷状态集 Q 包括这个自动机的所有的状态(states)， 然后一个输入字母表 ∑，包括所有可能的输入，一个转移函数 δ，从现在的状态接受一个输入到一个新状态的映射(这里还有一个扩展的转移函数后面再说), 一个初始状态 q0 表示从哪开始，和这个自动机的接收状态的集合 F 作为 Q 的一个子集。 关于这个扩展转移函数我们可以做类似的定义： δ: Q × ∑* → Q 这里的∑*代表的是由∑构成的字符串，也就是说自动机也可以对字符串的输入进行反应，这也是为了方便而定义的。 该装置接受的语言记作： L(M):= {w∈∑*|δ(q0, w)∈F} 就是说从初始状态出发读完输入串w之后所处的状态是一个接受状态，那么就接受这个串。被DFA识别的语言也叫 正则语言。 ","date":"2020-04-25","objectID":"/posts/theo/something-about-dfa-and-nfa/:1:0","tags":["theory of computation","theoretical computer science"],"title":"DFA与NFA的故事(一)","uri":"/posts/theo/something-about-dfa-and-nfa/"},{"categories":["学习笔记"],"content":"对于非确定型有穷自动机（NFA）的一些认识 对于非确定型有穷自动机(nondeterministic finite automaton 或者说 nichtdeterministischer endlicher Automat)与确定型的区别就在于非确定性：下一个状态可以不唯一确定，可以进行ε移动，多种选择(含0种选择)，我们还是来看看Tobias教授ppt上的定义： Ein nichtdeterministischer endlicher Automat (nondeterministic infinite automaton, NFA) ist ein 5-Tupel N = (Q, ∑, δ, q0, F), so dass Q, ∑, q0 und F sind wie bei einem DFA δ: Q × ∑ → P(Q) P(Q) = Menge aller Teilmengen von Q = 2^Q. Alternative: Relation δ ⊆ Q × ∑ × Q. 请注意这里的输入字母表 ∑ 是原本的 ∑和 ε的并, 也就还要加上长度为0的符号ε; 然后对于这里的转移函数 δ 在当前状态下读一个符号进入一个状态，因为不确定性有多种选择，所以进入多个状态，这里要用一个幂集来表示，也就是说这里的新状态是若干个Q的状态。同样这里对于转移函数 δ的扩展可以把 Q 改写为 P(Q),将原本的某一个状态扩展到多个状态的集合，这样就构成了多个备份。 该装置接受的语言记作： L(N):= {w∈∑*|δ({q0}, w) ∩ F ≠ Ø} 现在我们自然而然地会去想DFA与NFA之间有怎样的故事呢？DFA和NFA的能力是否一样？这也就是说它们是否识别同样的语言呢？ 我们知道DFA识别的语言NFA也可以识别，那么NFA识别的语言DFA是否也可以识别呢？这就涉及到它们的等价性的问题了。 ","date":"2020-04-25","objectID":"/posts/theo/something-about-dfa-and-nfa/:2:0","tags":["theory of computation","theoretical computer science"],"title":"DFA与NFA的故事(一)","uri":"/posts/theo/something-about-dfa-and-nfa/"},{"categories":["学习笔记"],"content":"正则运算的封闭性 我们想要去证明DFA和NFA的等价性还是先证明正则运算的封闭性(有时间再写吧，主要还是构造法) ","date":"2020-04-25","objectID":"/posts/theo/something-about-dfa-and-nfa/:3:0","tags":["theory of computation","theoretical computer science"],"title":"DFA与NFA的故事(一)","uri":"/posts/theo/something-about-dfa-and-nfa/"},{"categories":["学习笔记"],"content":"DFA与NFA的等价性 我们首先给出关于\"等价\"的定义，即两台机器识别同样的语言，它们的功能是一样的但是内部构造可能不一样；状态数，转移函数可能都不一样。于是我们接下来要证明的就是：每台NFA都有等价的DFA。(这里有一些题外话 如果是下推自动机或图灵机确定和非确定的故事就又需要我们去探索了) 这里我们就需要用到构造法来证明了hh 证明思路：对于给定的NFA，构造等价DFA，用DFA来模拟NFA，也即让DFA记住NFA的所有分支(理论上可行，因为NFA的k个状态是有穷的，于是所有可能的状态的子集合2^k个也是有穷的)，同时引入ε闭包的概念，对于每个状态子集合，经ε移动可达到的新状态子集合。 下面给出严格的证明： 设 NFA N = (Q, ∑, δ, q0, F),构造 DFA M = (Q', ∑, δ', q0', F'), L(M) = L(N). 令Q' = P(Q). 对R∈Q'和a∈∑, E(R)={q|从R出发沿0个或多个ε移动可达q}; δ'(R,a)=∪(r∈R)(R ∩ F ≠ Ø). ","date":"2020-04-25","objectID":"/posts/theo/something-about-dfa-and-nfa/:4:0","tags":["theory of computation","theoretical computer science"],"title":"DFA与NFA的故事(一)","uri":"/posts/theo/something-about-dfa-and-nfa/"},{"categories":["学习笔记"],"content":"写在最后 这一周THEO的课重要的部分大概是这些了，还有一些基本概念就没有写上来，至于这些语言的概念请参考Chomsky hierarchy, 下周的课看ppt应该是和正则语言以及上下文无关文法有关，也挺期待的呢。 ","date":"2020-04-25","objectID":"/posts/theo/something-about-dfa-and-nfa/:5:0","tags":["theory of computation","theoretical computer science"],"title":"DFA与NFA的故事(一)","uri":"/posts/theo/something-about-dfa-and-nfa/"}]